# WASS processing on the MET Norway post-processing infrastructure (PPI)

The wass-pyfuns/bash_scripts repository contains shell scripts to run WASS (pre/post) stereo video processing on the METNO PPI (bionic). The wass-pyfuns/ekok_config/ directory contains the configuration files for the Ekofisk stereo video system. If using these codes on another system, these files must be updated with that system's specifications (intrinsic calibration etc.).

Below is a quick tutorial for how to run the WASS processing pipeline (including some pre and post processing steps) using the python codes in the wass-pyfuns repository.

## Pre-processing of raw images

Extract the raw binary images from the .rar files into a chosen directory, and divide the images into a subdirectory for each batch (e.g. 20-minute subset). Naming convention used here is e.g. 1500/ for images covering the 15:00-15:20 time period. Put all images (i.e. both image pairs) in the same directory at this stage.

The WASS software cannot read the binary raw image format used on the Ekofisk platform (as of 2021), so the images have to be converted into a readable format for processing. To do this, copy the run_files/run_prep_images.bash script into the base directory that includes your image batch subdirectories (e.g. 1500/, 1520/, 1540/, etc.). Change the directory name in the loop within the script, and run. Example:

```
./run_prep_images.bash 1500 1520 1540
```
Running the script as above converts the raw images in the directories [1500, 1520, 1540] to .tif format, renames the files following WASS conventions and divides the image pairs into separate directories (cam0 for left camera images, cam1 for right camera images).


## Setting up a new WASS experiment

WASS experiments are generally located at /lustre/storeB/project/fou/om/stereowave/data/wass_output. Individual dates are typically given their own base directory, and the work directories for each 20-minute subset are placed inside these base directories. 

Example:
/lustre/storeB/project/fou/om/stereowave/data/wass_output/20191209/1200 is the working directory for the 20-minute subset from 12:00 to 12:20 on Dec 9 2019. 

Inside each working directory, copy the entire contents of the config directory from run_files/config into a directory named config. This directory includes the WASS configuration files for the Ekofisk stereo video system.

Also inside the working directory, make a new directory called input and move the cam0/ and cam1/ directories generated by the run_files/run_prep_images.bash script here. 

Copy the scripts run_files/run_wass_processing.bash, run_files/compute_mean_planes.bash and run_files/generate_grids.bash into the base directory and change the directory name (typically just the date) within the loop in each script.

An example base directory (20200521) with working directories (1500, 1520, ect.) and run scripts at this stage would look like this:

```
mikapm@xvis-m4a:/lustre/storeB/project/fou/om/stereowave/data/wass_output/20200521$ ls
1500  1520  1540  1600  1620  1640  compute_mean_planes.bash  generate_grids.bash  run_wass_processing.bash
```

To run the WASS pipeline, first log on to one of the PPI computing backends (so you don't use up all the computing power on PPI; the processing uses 24 processors in parallel by default):

```
qlogin -q research-bionic.q -l h_vmem=1G -l h_rt=06:00:00
```
or
```
qlogin -q research-el7.q -l h_vmem=1G -l h_rt=06:00:00
```
Define requested runtime with the h_rt option. 6 hours, as in the example above, should be enough to process one 20-minute batch.

When logged on to the computing backend, start the WASS pipeline on a new project (e.g. 1200/ in wass_output/20191209) by running

```
./run_wass_processing.bash 1200
```

This bash script calls the python script in stereo-wave/sw_pyfuns/wass_stuff/wass_launch.py with input argument '1200', which means we want to process the images in the 20191209/1200 directory. Note that if 20191209/1200/out already exists, the script will not run unless you give the extra input argument '-overwrite 1' to the python script. NB! Using the -overwrite arument, all existing output directories in the out/ directory will be removed and replaced.

If the WASS pipeline finishes processing without any issues there should be a file called plane_avg.txt in the working directory, and all timestamp directories in the out/ directory (e.g. out/000000_wd/) should have a mesh file named mesh_cam.xyzC. The most common reasons for the processing to fail is a synchronization error (i.e. an image pair hasn't been perfectly synchronized) or low quality input images. An example of a working directory that has been succesfully processed would look like this:

```
mikapm@xvis-m4a:/lustre/storeB/project/fou/om/stereowave/data/wass_output/20200521/1520$ ls
config  input  out  plane_avg.txt
```
## Mean sea plane estimation
The mean sea plane is used to convert the 3D point clouds generated by WASS into regular earth-projected grids. By default, WASS computes a mean sea plane over the entire stereo footprint. This may not be ideal, since the stereo reconstruction may be unreliable in the far field. For this reason it is recommended to estimate a new mean sea plane over a smaller region focused on the near field region of the stereo video reconstruction. This can be done using the `mean_plane.py` function, which is called by the `compute_mean_planes.bash` script. The syntax is similar to running the processing script:

```
./compute_mean_planes.bash 1200
```

Running this script generates a number of new sea plane files in the chosen WASS working directory. By default, the gridding function expects to find a file called "plane_avg_sub.txt", i.e. the mean sea plane estimated over a sub-region of the full footprint. The limits of this sub-region are defined in the `mean_plane.py` script.

# Gridding of the 3D meshes
Once the new mean sea plane has been estimated, the point clouds can be interpolated onto regular, earth-referenced $z(x,y)$ grids. At present, this is performed using the scipy.interpolate.griddata function with Delaunay triangulation and bilinear interpolation. Meshes from all WASS output folders within the chosen work directory are gridded and saved into one netcdf file in the grid/ directory in the WASS working directory. The gridding is a time-intensive process, and gridding one 20-minute sequence of meshes currently takes between 20-30 hours on the PPI computing backend. In my experience it is easier to get adequate wall time on the el7 compute nodes by logging in as follows:

```
qlogin -q research-el7.q -l h_vmem=5G -l h_rt=36:00:00
```

Due to the long wall time requirement it is also recommended to run the processing in a separate `screen`. The syntax for running the gridding is again similar to the other processing scripts:

```
./generate_grids.bash 1200
```


## Authors

* **Mika Malila** - *Initial work* - [stereo-wave](https://github.com/mikapm/stereo-wave)

